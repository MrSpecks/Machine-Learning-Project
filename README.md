# ğŸ  Housing Prices: Advanced Regression Techniques
## Refactored Exploratory Data Analysis & Dashboard Backend

## ğŸ“Š Project Overview
This project provides a **refactored, production-ready** analysis of the Kaggle Housing Prices dataset. The analysis has been restructured into modular components suitable for dashboard integration while maintaining all original insights and findings.

**Project Type:** Machine Learning Developer Intern Technical Assessment  
**Domain:** Real Estate / Housing Market Analysis  
**Objective:** Predict house sale prices using advanced data science techniques  
**Version:** 2.0 (Refactored for Dashboard Backend)

## ğŸ—‚ï¸ Dataset Information

### Primary Dataset
- **Source:** [Kaggle - House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
- **Location:** `./house-prices-advanced-regression-techniques/train.csv`
- **Size:** 1,460 observations Ã— 80+ features (after engineering)
- **Target Variable:** SalePrice (continuous, $34,900 - $755,000)
- **Dataset Type:** Supervised Learning (Regression)

### Additional Files
- `test.csv` - Test dataset for predictions
- `data_description.txt` - Detailed feature descriptions
- `sample_submission.csv` - Submission format

## ğŸš€ Quick Start

### Prerequisites
- **Python:** 3.8 or higher
- **Jupyter:** Notebook or JupyterLab
- **Memory:** Minimum 4GB RAM recommended
- **Storage:** 100MB free space

### Installation Steps
1. **Clone/Download Repository:**
   ```bash
   git clone https://github.com/MrSpecks/Machine-Learning-Project
   cd Machine-Learning-Project
   ```

2. **Install Required Libraries:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Verify Installation:**
   ```bash
   python -c "import pandas, numpy, matplotlib, seaborn; print('âœ… All libraries installed successfully!')"
   ```

## â–¶ï¸ Running the Refactored Analysis

### Main Refactored Notebook
1. **Start Jupyter Notebook:**
   ```bash
   jupyter notebook
   ```

2. **Open Refactored Analysis:**
   - Navigate to `Housing_EDA_Refactored.ipynb`
   - Run all cells sequentially (Cell â†’ Run All)

3. **Expected Runtime:** 3-5 minutes for complete analysis

### Using the Modular Components

#### Data Loading and Feature Engineering
```python
from housing_data_loader import get_analysis_ready_data, get_feature_summary

# Load the complete analysis-ready dataset
df = get_analysis_ready_data("house-prices-advanced-regression-techniques/train.csv")

# Get feature categories
feature_summary = get_feature_summary(df)
```

#### Analysis and Metrics
```python
from housing_analysis_metrics import (
    get_top_correlations, calculate_neighborhood_stats, 
    filter_dataset, get_price_distribution_stats
)

# Get top price drivers
top_correlations = get_top_correlations(df, n_top=10)

# Calculate neighborhood statistics
neighborhood_stats = calculate_neighborhood_stats(df)

# Filter dataset for dashboard
filtered_df = filter_dataset(df, {
    'Neighborhood': ['Northridge', 'Stone Brook'],
    'OverallQual': (7, 10)
})
```

## ğŸ“ Project Structure
```
Machine-Learning-Project/
â”œâ”€â”€ house-prices-advanced-regression-techniques/
â”‚   â”œâ”€â”€ train.csv                    # Original training dataset
â”‚   â”œâ”€â”€ test.csv                     # Test dataset
â”‚   â”œâ”€â”€ train_cleaned.csv            # Cleaned dataset (EDA output)
â”‚   â”œâ”€â”€ train_engineered.csv         # Enhanced dataset (Feature Engineering output)
â”‚   â”œâ”€â”€ data_description.txt         # Feature descriptions
â”‚   â””â”€â”€ sample_submission.csv        # Submission format
â”œâ”€â”€ housing_data_loader.py           # ğŸ”§ Data loading and feature engineering module
â”œâ”€â”€ housing_analysis_metrics.py      # ğŸ“Š Business logic and calculations module
â”œâ”€â”€ Housing_EDA_Refactored.ipynb    # ğŸ““ Refactored analysis notebook
â”œâ”€â”€ housing_eda_kagiso_mfusi.ipynb       # Original EDA notebook
â”œâ”€â”€ housing_feature_engineering_kagiso_mfusi.ipynb # Original feature engineering
â”œâ”€â”€ DATASET_INFO.md                  # Detailed dataset documentation
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ prompts/                        # Documentation prompts
    â”œâ”€â”€ Convert-to-dasboard.txt
    â””â”€â”€ structure-and-documentation-of-notebook.txt
```

## ğŸ¯ Key Findings Summary

### ğŸ“ˆ **Primary Price Drivers**
â€¢ **OverallQual** (r=0.79) - Quality dominates pricing over size
â€¢ **GrLivArea** (r=0.71) - Living area is the strongest size predictor
â€¢ **GarageCars** (r=0.64) - Garage capacity more predictive than bedroom count
â€¢ **Location** - Neighborhood creates 3x price variation ($100k-$300k range)

### ğŸ” **Surprising Insights**
â€¢ **Quality > Size** - OverallQual beats GrLivArea in importance hierarchy
â€¢ **All Outliers High-Value** - No low-value outliers, only luxury homes identified
â€¢ **Bedroom Count Weak** - BedroomAbvGr only r=0.17 correlation with price
â€¢ **Age Plateau Effect** - Depreciation stops after 50 years, historic homes maintain value

### ğŸ“Š **Data Quality Excellence**
â€¢ **Zero Missing Values** - All 19 features with missing data successfully imputed
â€¢ **No Duplicates** - Clean dataset with unique property records
â€¢ **Multicollinearity Documented** - High correlations identified for modeling consideration
â€¢ **Outliers Retained** - Legitimate luxury properties preserved for analysis

### ğŸ—ï¸ **Feature Engineering Success**
â€¢ **50+ Features Created** - Including TotalSF, TotalBath, HouseAge, QualitySize interactions
â€¢ **High-Impact Features** - QualitySize, QualityLivArea show strong predictive power
â€¢ **Expected Performance Gain** - RÂ² improvement from 0.85 to 0.90+ with engineered features

### ğŸ’¼ **Business Insights**
â€¢ **Sellers:** Invest in quality renovations over size expansion for maximum ROI
â€¢ **Buyers:** Don't overpay for square footage alone - quality and location matter more
â€¢ **Agents:** Use neighborhood-specific comparables for accurate pricing
â€¢ **Developers:** Location first, then balance quality and size for optimal market positioning

### ğŸ¤– **Modeling Readiness**
â€¢ **Clean Dataset** - Ready for immediate modeling with zero preprocessing needed
â€¢ **Feature-Rich** - 130+ total features (80 original + 50+ engineered) available
â€¢ **Validation Complete** - All features tested for correlation and multicollinearity
â€¢ **Expected RÂ² Performance** - 0.85-0.92 range achievable with proper model selection

## ğŸ”§ Refactoring Improvements

### **Modular Architecture**
- **`housing_data_loader.py`**: Centralized data loading, cleaning, and feature engineering
- **`housing_analysis_metrics.py`**: Business logic functions for calculations and insights
- **Refactored Notebook**: Clean, documented analysis workflow

### **Dashboard Integration Ready**
- **Filtering Functions**: `filter_dataset()` supports dynamic data filtering
- **Metric Functions**: All analysis functions work with filtered datasets
- **Consistent API**: Standardized function signatures and return types

### **Production Quality**
- **Comprehensive Documentation**: Docstrings for all functions
- **Type Hints**: Full type annotation for better IDE support
- **Error Handling**: Robust error checking and informative messages
- **Extensible Design**: Easy to add new features and analysis functions

## ğŸ“‹ Requirements
```
# Core Data Science Libraries
pandas>=2.0.0
numpy>=1.24.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Statistical Analysis
scipy>=1.10.0

# Machine Learning
scikit-learn>=1.3.0

# Jupyter Environment
jupyter>=1.0.0
ipykernel>=6.0.0

# Optional: For enhanced dashboard development
streamlit>=1.28.0
plotly>=5.17.0
```

## ğŸš€ Streamlit Dashboard

### Running the Interactive Dashboard

1. **Install Dashboard Dependencies:**
   ```bash
   pip install streamlit plotly
   ```

2. **Launch the Dashboard:**
   ```bash
   streamlit run streamlit_app.py
   ```

3. **Access the Dashboard:**
   - Open your browser to `http://localhost:8501`
   - Use the sidebar filters to explore the data interactively

### Dashboard Features

**ğŸ“Š Key Performance Indicators (KPIs):**
- Median Sale Price with trend indicators
- Average Price per Square Foot
- Total Properties Sold
- Average Overall Quality

**ğŸ“ˆ Interactive Charts:**
- **Price vs. Size Scatter Plot**: Living area vs. sale price (colored by quality)
- **Neighborhood Box Plots**: Price distribution by neighborhood
- **Quality Bar Chart**: Median prices by quality rating
- **Correlation Heatmap**: Key feature correlations with sale price

**ğŸ” Dynamic Filtering:**
- Neighborhood selection (multiselect)
- Overall Quality range (slider)
- Year Sold selection (multiselect)
- Price Range (slider)

**ğŸ“‹ Additional Statistics:**
- Average Property Age at Sale
- Average Garage Capacity

### Dashboard Integration Example

```python
from housing_data_loader import get_analysis_ready_data
from housing_analysis_metrics import (
    get_top_correlations, calculate_neighborhood_stats, 
    filter_dataset, get_price_distribution_stats
)

# Load data
df = get_analysis_ready_data()

# Apply user filters (e.g., from Streamlit dashboard)
filters = {
    'Neighborhood': ['Northridge', 'Stone Brook'],
    'OverallQual': (7, 10),
    'YearBuilt': (2000, 2010)
}
filtered_df = filter_dataset(df, filters)

# Get insights for filtered data
correlations = get_top_correlations(filtered_df)
neighborhood_stats = calculate_neighborhood_stats(filtered_df)
price_stats = get_price_distribution_stats(filtered_df)

# Use these metrics in your dashboard
```

## ğŸ‘¨â€ğŸ’» Author Information

**Full Name:** Kagiso Mfusi  
**Email:** Kagisomfusi@outlook.com  
**LinkedIn:** [https://www.linkedin.com/in/kagiso-mfusi-95b329224](https://www.linkedin.com/in/kagiso-mfusi-95b329224)  
**Project Date:** October 24, 2025 
**Assessment:** Machine Learning Developer Technical Assessment

## ğŸ“„ License
This project is created for educational and assessment purposes only. The dataset is sourced from Kaggle's public House Prices competition.
